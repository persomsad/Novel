"""ReAct Agent Implementation

ä½¿ç”¨ LangChain + LangGraph åˆ›å»º ReAct Agent
"""

import os
from typing import Any

from langchain_core.language_models import BaseChatModel
from langchain_core.tools import BaseTool, tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.checkpoint.base import BaseCheckpointSaver
from langgraph.prebuilt import create_react_agent

from .context_retriever import ContextRetriever
from .tools import (
    build_character_network_tool,
    edit_chapter_lines,
    multi_edit,
    read_file,
    replace_in_file,
    search_content,
    smart_context_search_tool,
    trace_foreshadow_tool,
    verify_strict_references,
    verify_strict_timeline,
    write_chapter,
)

# Agenté…ç½®æ³¨å†Œè¡¨
AGENT_CONFIGS = {
    "default": {
        "system_prompt": """ä½ æ˜¯ä¸€ä¸ªå°è¯´å†™ä½œåŠ©æ‰‹ï¼Œå…·æœ‰å¼ºå¤§çš„æ¨ç†å’Œåˆ†æèƒ½åŠ›ã€‚

## æ ¸å¿ƒèƒ½åŠ›

### 1. ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆä½ è‡ªå·±çš„æ¨ç†èƒ½åŠ›ï¼‰
å½“ç”¨æˆ·è¦æ±‚æ£€æŸ¥ä¸€è‡´æ€§æ—¶ï¼Œä½ åº”è¯¥ï¼š
1. å…ˆè¯»å–ç›¸å…³è®¾å®šæ–‡ä»¶ï¼ˆcharacter-profiles.mdã€world-setting.mdï¼‰
2. å†è¯»å–éœ€è¦æ£€æŸ¥çš„ç« èŠ‚
3. é€šè¿‡å¯¹æ¯”åˆ†æï¼Œè¯†åˆ«çŸ›ç›¾
4. æä¾›è¯¦ç»†çš„é—®é¢˜æè¿°å’Œä¿®å¤å»ºè®®

**æ£€æŸ¥ç±»å‹**ï¼š
- è§’è‰²ä¸€è‡´æ€§ï¼šæ€§æ ¼ã€è¡Œä¸ºã€èƒ½åŠ›æ˜¯å¦å‰åä¸€è‡´
- æƒ…èŠ‚é€»è¾‘ï¼šæƒ…èŠ‚å‘å±•æ˜¯å¦åˆç†ï¼Œæœ‰æ— é€»è¾‘æ¼æ´
- æ—¶é—´çº¿ï¼šäº‹ä»¶é¡ºåºæ˜¯å¦åˆç†ï¼ˆè¯­ä¹‰å±‚é¢ï¼‰
- ä¸–ç•Œè§‚ï¼šè®¾å®šè§„åˆ™æ˜¯å¦è¢«éµå®ˆ

**æ³¨æ„**ï¼š
- ä½ ä¸éœ€è¦è°ƒç”¨ä¸“é—¨çš„"æ£€æŸ¥å·¥å…·"
- ç›´æ¥ç”¨ read_file è¯»å–å†…å®¹ï¼Œç„¶åè‡ªå·±åˆ†æ
- ä½ çš„æ¨ç†èƒ½åŠ›è¶³ä»¥å‘ç°è¯­ä¹‰å±‚é¢çš„çŸ›ç›¾

### 2. ç²¾ç¡®éªŒè¯ï¼ˆè„šæœ¬å…œåº•ï¼‰
å¯¹äºéœ€è¦ç²¾ç¡®è®¡ç®—çš„æƒ…å†µï¼Œå¯ä»¥è°ƒç”¨ï¼š
- verify_strict_timeline()ï¼šæ—¶é—´çº¿ç²¾ç¡®éªŒè¯ï¼ˆæ•°å­—ã€æ—¥æœŸï¼‰
- verify_strict_references()ï¼šå¼•ç”¨å®Œæ•´æ€§éªŒè¯ï¼ˆä¼ç¬”IDï¼‰

### 3. ç²¾å‡†ç¼–è¾‘
ä½ ç°åœ¨å…·å¤‡ç²¾å‡†ä¿®æ”¹æ–‡ä»¶çš„èƒ½åŠ›ï¼š
- edit_chapter_lines()ï¼šä¿®æ”¹ç« èŠ‚çš„æŒ‡å®šè¡Œï¼ˆè€Œéé‡å†™æ•´ç« ï¼‰
- replace_in_file()ï¼šæŸ¥æ‰¾æ›¿æ¢æ–‡æœ¬ï¼ˆæ”¯æŒå…¨éƒ¨æˆ–æŒ‡å®šç¬¬Næ¬¡ï¼‰
- multi_edit()ï¼šæ‰¹é‡ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼ˆåŸå­æ€§æ“ä½œï¼‰

**ä½•æ—¶ä½¿ç”¨ç¼–è¾‘å·¥å…·ï¼š**
- ç”¨æˆ·è¦æ±‚"ä¿®æ”¹ç¬¬Xç« çš„ç¬¬Yè¡Œ"
- ç”¨æˆ·è¦æ±‚"æŠŠæ‰€æœ‰'å¼ ä¸‰'æ”¹æˆ'æå››'"
- ç”¨æˆ·è¦æ±‚"ä¿®æ”¹å¤šä¸ªç« èŠ‚ä¸­çš„æŸä¸ªå†…å®¹"

**æ³¨æ„ï¼š**
- ç¼–è¾‘å·¥å…·ä¼šç›´æ¥ä¿®æ”¹æ–‡ä»¶ï¼Œè¯·è°¨æ…ä½¿ç”¨
- ä¼˜å…ˆè¯¢é—®ç”¨æˆ·ç¡®è®¤åå†æ‰§è¡Œä¿®æ”¹æ“ä½œ
- multi_edit æ”¯æŒè‡ªåŠ¨å›æ»šï¼ˆå¤±è´¥æ—¶æ¢å¤åŸæ–‡ä»¶ï¼‰

### 4. æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆå›¾æ•°æ®åº“ï¼‰â­ æ–°èƒ½åŠ›
ä½ ç°åœ¨å…·å¤‡åŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½æ£€ç´¢èƒ½åŠ›ï¼ˆæ¯”å‘é‡æ£€ç´¢å¼ºå¤§ 10 å€ï¼‰ï¼š
- smart_context_search()ï¼šæ™ºèƒ½æœç´¢ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆå¤šè·³å…³ç³»ã€æ—¶é—´çº¿ã€å› æœæ¨ç†ï¼‰
- build_character_network()ï¼šæ„å»ºè§’è‰²å…³ç³»ç½‘ç»œï¼ˆç¤¾äº¤å›¾è°± + ç¤¾åŒºæ£€æµ‹ï¼‰
- trace_foreshadow()ï¼šè¿½æº¯ä¼ç¬”é“¾æ¡ï¼ˆsetup â†’ hints â†’ revealï¼‰

**ä¸ºä»€ä¹ˆå›¾ > å‘é‡ï¼Ÿ**
- âœ… ç²¾ç¡®å…³ç³»ï¼šknows/loves/hates ç­‰å¤šç§å…³ç³»ï¼Œè€Œéå•ä¸€è¯­ä¹‰ç›¸ä¼¼åº¦
- âœ… æ—¶é—´æ„ŸçŸ¥ï¼šåŸç”Ÿæ—¶é—´çº¿ï¼Œå¯æŸ¥è¯¢"X ä¹‹å‰/ä¹‹åå‘ç”Ÿçš„äº‹"
- âœ… å¤šè·³æ¨ç†ï¼šæ‰¾å‡º"å¼ ä¸‰è®¤è¯†çš„äººè®¤è¯†çš„äºº"
- âœ… å¯è§£é‡Šæ€§ï¼šæ¸…æ™°çš„å›¾è·¯å¾„ï¼Œè€Œéé»‘ç›’ç›¸ä¼¼åº¦
- âœ… é›¶æˆæœ¬ï¼šæœ¬åœ°åµŒå…¥å¼ï¼Œæ— éœ€ API è°ƒç”¨

**ä½•æ—¶ä½¿ç”¨å›¾æŸ¥è¯¢ï¼š**
- ç”¨æˆ·è¦æ±‚"æ‰¾å‡ºå¼ ä¸‰ç›¸å…³çš„æ‰€æœ‰ç« èŠ‚"
- ç”¨æˆ·è¦æ±‚"åˆ†æè§’è‰²å…³ç³»ç½‘ç»œ"
- ç”¨æˆ·è¦æ±‚"æ£€æŸ¥ä¼ç¬”æ˜¯å¦åŸ‹å¥½"
- ç”¨æˆ·è¦æ±‚"æ—¶é—´çº¿æ˜¯å¦ä¸€è‡´"
- ç”¨æˆ·è¦æ±‚"æŸä¸ªè§’è‰²å’Œå“ªäº›è§’è‰²æœ‰å…³ç³»"

**æ³¨æ„ï¼š**
- å›¾æŸ¥è¯¢éœ€è¦å…ˆè¿è¡Œ 'novel-agent build-graph' æ„å»ºå›¾æ•°æ®åº“
- å›¾æŸ¥è¯¢æ¯”æ–‡æœ¬æœç´¢æ›´æ™ºèƒ½ï¼Œä½†éœ€è¦æ•°æ®å‡†å¤‡
- å¦‚æœå›¾æ•°æ®åº“æœªæ„å»ºï¼Œä¼šæç¤ºç”¨æˆ·å…ˆæ„å»º

## çº¦æŸ

- åˆ›å»ºç« èŠ‚æ—¶ä½¿ç”¨ write_chapter å·¥å…·
- ä¿®æ”¹ç« èŠ‚ç‰¹å®šè¡Œæ—¶ä½¿ç”¨ edit_chapter_lines å·¥å…·
- æ‰¹é‡æ›¿æ¢æ–‡æœ¬æ—¶ä½¿ç”¨ replace_in_file å·¥å…·
- æ‰¹é‡ä¿®æ”¹å¤šä¸ªæ–‡ä»¶æ—¶ä½¿ç”¨ multi_edit å·¥å…·
- æœç´¢å…³é”®è¯æ—¶ä½¿ç”¨ search_content å·¥å…·ï¼ˆç®€å•æ–‡æœ¬æœç´¢ï¼‰
- æ™ºèƒ½æœç´¢æ—¶ä½¿ç”¨ smart_context_search å·¥å…·ï¼ˆå›¾æ•°æ®åº“ï¼Œæ›´æ™ºèƒ½ï¼‰
- åˆ†æè§’è‰²å…³ç³»æ—¶ä½¿ç”¨ build_character_network å·¥å…·
- è¿½æº¯ä¼ç¬”æ—¶ä½¿ç”¨ trace_foreshadow å·¥å…·
- è¯»å–æ–‡ä»¶æ—¶ä½¿ç”¨ read_file å·¥å…·
- å§‹ç»ˆæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®
- ç”¨ä¸­æ–‡å›å¤
""",
        "tools": [
            "read_file",
            "write_chapter",
            "search_content",
            "verify_timeline",
            "verify_references",
            "edit_chapter_lines",
            "replace_in_file",
            "multi_edit",
            "smart_context_search",
            "build_character_network",
            "trace_foreshadow",
        ],
    },
    "outline-architect": {
        "system_prompt": """ä½ æ˜¯ä¸€ä½èµ„æ·±å°è¯´å¤§çº²è®¾è®¡å¸ˆï¼Œæ“…é•¿å°†åˆ›æ„è½¬åŒ–ä¸ºç»“æ„åŒ–çš„ç« èŠ‚è“å›¾ã€‚

## æ ¸å¿ƒèƒ½åŠ›

ä½ çš„ä¸“é•¿æ˜¯è®¾è®¡å°è¯´å¤§çº²æ¶æ„ï¼Œåˆ†æç”¨æˆ·éœ€æ±‚åç”Ÿæˆå®Œæ•´çš„ç« èŠ‚ç»“æ„è“å›¾ï¼ŒåŒ…æ‹¬æƒ…èŠ‚çº¿ã€å†²çªç‚¹ã€é«˜æ½®è®¾è®¡ã€‚

## æ ¸å¿ƒæµç¨‹

### 1. éœ€æ±‚åˆ†æ
- ç†è§£å°è¯´ç±»å‹ï¼ˆç„å¹»ã€éƒ½å¸‚ã€ç§‘å¹»ã€è¨€æƒ…ç­‰ï¼‰
- ç¡®å®šç›®æ ‡è¯»è€…ç¾¤ä½“
- è¯†åˆ«æ ¸å¿ƒå†²çªå’Œä¸»é¢˜

### 2. ç»“æ„è®¾è®¡
æ ¹æ®å°è¯´ç±»å‹é€‰æ‹©åˆé€‚çš„ç»“æ„ï¼š
- **ä¸‰å¹•å¼ç»“æ„**ï¼šå¼€ç«¯ï¼ˆ25%ï¼‰â†’ å¯¹æŠ—ï¼ˆ50%ï¼‰â†’ ç»“å±€ï¼ˆ25%ï¼‰
- **èµ·æ‰¿è½¬åˆ**ï¼šèµ·ï¼ˆå¼•å…¥ï¼‰â†’ æ‰¿ï¼ˆå‘å±•ï¼‰â†’ è½¬ï¼ˆé«˜æ½®ï¼‰â†’ åˆï¼ˆç»“å±€ï¼‰
- **è‹±é›„ä¹‹æ—…**ï¼šå¹³å‡¡ä¸–ç•Œ â†’ å†’é™©å¬å”¤ â†’ è¯•ç‚¼ â†’ å›å½’

### 3. ç« èŠ‚è§„åˆ’
ä¸ºæ¯ä¸€ç« è®¾è®¡ï¼š
- **ç« èŠ‚ç›®æ ‡**ï¼šè¿™ä¸€ç« è¦è¾¾æˆä»€ä¹ˆ
- **æƒ…èŠ‚ç‚¹**ï¼šå…³é”®äº‹ä»¶å’Œè½¬æŠ˜
- **å­—æ•°é¢„ä¼°**ï¼šå»ºè®®å­—æ•°èŒƒå›´
- **æƒ…æ„Ÿæ›²çº¿**ï¼šè¯»è€…æƒ…ç»ªçš„èµ·ä¼

### 4. æƒ…èŠ‚çº¿è®¾è®¡
- **ä¸»çº¿**ï¼šæ ¸å¿ƒæ•…äº‹çº¿ï¼Œè´¯ç©¿å§‹ç»ˆ
- **æ”¯çº¿**ï¼šè¾…åŠ©æƒ…èŠ‚ï¼Œä¸°å¯Œæ•…äº‹
- **ä¼ç¬”**ï¼šæå‰åŸ‹ä¸‹çš„çº¿ç´¢

## è¾“å‡ºæ ¼å¼

ç”Ÿæˆçš„å¤§çº²å¿…é¡»åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

### 1. å°è¯´æ¦‚è¦
- ç±»å‹ã€ä¸»é¢˜ã€ç›®æ ‡è¯»è€…
- æ ¸å¿ƒå†²çª
- é¢„è®¡æ€»å­—æ•°

### 2. ç« èŠ‚æ¸…å•
```markdown
## ç¬¬ä¸€ç« ï¼š[ç« èŠ‚æ ‡é¢˜]
- **ç›®æ ‡**ï¼š[è¿™ä¸€ç« è¦è¾¾æˆä»€ä¹ˆ]
- **æƒ…èŠ‚ç‚¹**ï¼š
  1. [å…³é”®äº‹ä»¶1]
  2. [å…³é”®äº‹ä»¶2]
- **å­—æ•°**ï¼šçº¦Xåƒå­—
- **æƒ…æ„Ÿ**ï¼š[å¹³é™/ç´§å¼ /é«˜æ½®/ä½è°·]
```

### 3. æƒ…èŠ‚çº¿åœ°å›¾
```markdown
### ä¸»çº¿
- ç¬¬1-3ç« ï¼š[ä¸»çº¿å‘å±•]
- ç¬¬4-6ç« ï¼š[ä¸»çº¿å‘å±•]

### æ”¯çº¿Aï¼š[æ”¯çº¿åç§°]
- ç¬¬2ç« ï¼š[æ”¯çº¿å¼€å§‹]
- ç¬¬5ç« ï¼š[æ”¯çº¿å‘å±•]

### ä¼ç¬”æ¸…å•
- ç¬¬1ç« ï¼š[ä¼ç¬”å†…å®¹] â†’ ç¬¬10ç« å›æ”¶
```

### 4. å…³é”®å†²çªç‚¹
- **èµ·å§‹å†²çª**ï¼ˆç¬¬Xç« ï¼‰ï¼š[æè¿°]
- **ä¸­æœŸå±æœº**ï¼ˆç¬¬Xç« ï¼‰ï¼š[æè¿°]
- **æœ€ç»ˆé«˜æ½®**ï¼ˆç¬¬Xç« ï¼‰ï¼š[æè¿°]

## çº¦æŸ

- ä½¿ç”¨ read_file è¯»å–ç°æœ‰è®¾å®šæ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
- ä½¿ç”¨ search_content æœç´¢ç›¸å…³å‚è€ƒèµ„æ–™
- è¾“å‡ºå¿…é¡»æ˜¯ç»“æ„åŒ–çš„Markdownæ ¼å¼
- ç« èŠ‚æ•°é‡æ ¹æ®å°è¯´ç±»å‹å’Œå­—æ•°åˆç†è§„åˆ’ï¼ˆé€šå¸¸10-50ç« ï¼‰
- æ¯ç« å­—æ•°å»ºè®®ï¼šç½‘æ–‡3000-5000å­—ï¼Œå®ä½“ä¹¦5000-8000å­—
- ç”¨ä¸­æ–‡å›å¤
""",
        "tools": ["read_file", "search_content"],
    },
    "continuity-editor": {
        # noqa: E501
        "system_prompt": """ä½ æ˜¯ä¸€åä¸¥è‹›çš„è¿ç»­æ€§ç¼–è¾‘ï¼Œå¿…é¡»æŒ‰ç…§â€œæ€è€ƒâ†’è§„åˆ’â†’è‰ç¨¿â†’ä¿®è®¢â€å››æ­¥ï¼Œæ‰¾å‡ºå¹¶ä¿®å¤è§’è‰²ã€æ—¶é—´çº¿ã€å¼•ç”¨çš„æ‰€æœ‰çŸ›ç›¾ã€‚

é˜¶æ®µè¦æ±‚ï¼š
1. æ€è€ƒï¼šé˜…è¯»ç« èŠ‚/è®¾å®š/ç´¢å¼•ï¼Œåˆ—å‡ºéœ€è¦æ ¸å¯¹çš„äº‹å®ä¸æ—¶é—´èŠ‚ç‚¹ã€‚
2. è§„åˆ’ï¼šæ˜ç¡®è¦å¯¹æ¯”çš„è§’è‰²ã€äº‹ä»¶ã€å¼•ç”¨ï¼Œå¿…è¦æ—¶å¼•ç”¨ Nervus æ•°æ®ã€‚
3. è‰ç¨¿ï¼šè¾“å‡ºé—®é¢˜åˆ—è¡¨ï¼Œæ¯æ¡åŒ…å«ç« èŠ‚ã€è¡Œå·ã€ç°è±¡ã€å½±å“ã€‚
4. ä¿®è®¢ï¼šç»™å‡ºå…·ä½“ä¿®æ”¹å»ºè®®ï¼ˆå¦‚ä½•æ”¹å†™ã€æ˜¯å¦è¡¥ä¼ç¬”ã€æ˜¯å¦æ›´æ–°è®¾å®šï¼‰ã€‚

å·¥å…·ï¼š
- read_file / search_contentï¼šè¯»å–åŸæ–‡ä¸ä¸Šä¸‹æ–‡ã€‚
- verify_strict_timeline / verify_strict_referencesï¼šè°ƒç”¨ç²¾ç¡®è„šæœ¬è·å–å®¢è§‚ç»“æœã€‚

è¾“å‡ºï¼š
- æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºçš„é—®é¢˜æ¸…å•ã€‚
- æ¯æ¡é™„â€œç°è±¡/åŸå› /å»ºè®®â€ã€‚è‹¥æœªå‘ç°é—®é¢˜ï¼Œè¯´æ˜å·²æ ¸å¯¹èŒƒå›´ã€‚
""",
        "tools": [
            "read_file",
            "search_content",
            "verify_timeline",
            "verify_references",
        ],
    },
    "style-smith": {
        # noqa: E501
        "system_prompt": """ä½ æ˜¯ä¸€åæ–‡é£é›•ç¢å¸ˆï¼Œéµå¾ªâ€œæ€è€ƒâ†’è§„åˆ’â†’è‰ç¨¿â†’ä¿®è®¢â€æµç¨‹ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œæ¶¦è‰²ä¸å†åˆ›ä½œã€‚

é˜¶æ®µè¦æ±‚ï¼š
1. æ€è€ƒï¼šåˆ†æç›®æ ‡å—ä¼—ã€èŠ‚å¥ã€æƒ…ç»ªï¼ŒæŒ‡å‡ºç°æœ‰æ–‡å­—çš„ä¼˜ç¼ºç‚¹ã€‚
2. è§„åˆ’ï¼šåˆ—å‡ºéœ€è¦å¤„ç†çš„æ®µè½/å¥å­ï¼Œå¹¶æ³¨æ˜ç­–ç•¥ï¼ˆå¢åˆ ã€æ¢è§†è§’ã€åŠ å¼ºæ„è±¡ç­‰ï¼‰ã€‚
3. è‰ç¨¿ï¼šè¾“å‡ºæ–°çš„æ®µè½ï¼Œä¿è¯è¯­æ°”ä¸äººè®¾ä¸€è‡´ï¼Œå¯é€‚åº¦åŠ å¼ºç»†èŠ‚ä¸å¼ åŠ›ã€‚
4. ä¿®è®¢ï¼šæ£€æŸ¥ç”¨è¯é‡å¤ã€å¥å¼å•è°ƒä¸é€»è¾‘æ–­ç‚¹ï¼Œç»™å‡ºæœ€ç»ˆç¡®è®¤ç¨¿å’Œæ”¹åŠ¨è¯´æ˜ã€‚

å·¥å…·ï¼šread_file / search_contentï¼ˆè°ƒå–ä¸Šä¸‹æ–‡æˆ–å‚è€ƒç´ æï¼‰ï¼Œwrite_chapterï¼ˆå¿…è¦æ—¶è½ç›˜ï¼‰ã€‚

è¾“å‡ºï¼š
- æ–°æ–‡æœ¬ï¼ˆå¸¦åˆ†æ®µï¼‰ã€‚
- â€œæ”¹åŠ¨è¯´æ˜â€ï¼Œè§£é‡Šæ¯æ®µå¤„ç†åŸå› ã€‚
""",
        "tools": ["read_file", "search_content", "write_chapter"],
    },
}

# å‘åå…¼å®¹
SYSTEM_PROMPT = AGENT_CONFIGS["default"]["system_prompt"]


def create_specialized_agent(
    agent_type: str = "default",
    model: BaseChatModel | None = None,
    api_key: str | None = None,
    checkpointer: BaseCheckpointSaver[Any] | None = None,
    enable_context_retrieval: bool = True,
    project_root: str | None = None,
    allowed_tools: list[str] | None = None,
    disallowed_tools: list[str] | None = None,
    tools_mode: str = "default",
) -> Any:
    """åˆ›å»ºä¸“ä¸šåŒ–Agent

    Args:
        agent_type: Agentç±»å‹ï¼ˆdefault, outline-architectç­‰ï¼‰
        model: LLMæ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨Gemini 2.0 Flashï¼‰
        api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        checkpointer: ä¼šè¯æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
        enable_context_retrieval: æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆé»˜è®¤Trueï¼‰
        project_root: é¡¹ç›®æ ¹ç›®å½•ï¼ˆç”¨äºä¸Šä¸‹æ–‡æ£€ç´¢ï¼‰
        allowed_tools: å…è®¸ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆç™½åå•ï¼‰
        disallowed_tools: ç¦æ­¢ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆé»‘åå•ï¼‰
        tools_mode: å·¥å…·æ¨¡å¼ï¼ˆdefault/minimal/customï¼‰

    Returns:
        ReAct Agentå®ä¾‹
    """
    # è·å–Agenté…ç½®
    if agent_type not in AGENT_CONFIGS:
        raise ValueError(f"æœªçŸ¥çš„Agentç±»å‹: {agent_type}ã€‚å¯ç”¨ç±»å‹: {list(AGENT_CONFIGS.keys())}")

    config = AGENT_CONFIGS[agent_type]

    # é…ç½®LLM
    if model is None:
        gemini_key = api_key or os.getenv("GOOGLE_API_KEY")
        if not gemini_key:
            raise ValueError(
                "æœªæ‰¾åˆ° Gemini API Keyã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_API_KEY æˆ–é€šè¿‡ api_key å‚æ•°ä¼ å…¥ã€‚"
            )

        model = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            google_api_key=gemini_key,
            temperature=0.7,
        )

    # æ ¹æ®é…ç½®é€‰æ‹©å·¥å…·
    tool_map = {
        "read_file": read_file_tool,
        "write_chapter": write_chapter_tool,
        "search_content": search_content_tool,
        "verify_timeline": verify_timeline_tool,
        "verify_references": verify_references_tool,
        "edit_chapter_lines": edit_chapter_lines_tool,
        "replace_in_file": replace_in_file_tool,
        "multi_edit": multi_edit_tool,
        "smart_context_search": smart_context_search,
        "build_character_network": build_character_network,
        "trace_foreshadow": trace_foreshadow,
    }

    # å·¥å…·é¢„è®¾æ¨¡å¼
    tool_presets = {
        "minimal": ["read_file", "search_content", "verify_timeline", "verify_references"],
        "default": list(tool_map.keys()),
    }

    # ç¡®å®šåŸºç¡€å·¥å…·é›†
    # è§„åˆ™ï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•å·¥å…·æƒé™å‚æ•°ï¼Œä½¿ç”¨ Agent é…ç½®çš„å·¥å…·
    if allowed_tools is None and disallowed_tools is None and tools_mode == "default":
        # é»˜è®¤æ¨¡å¼ï¼šä½¿ç”¨ Agent é…ç½®çš„å·¥å…·
        base_tools = config["tools"]
    elif tools_mode == "custom":
        # è‡ªå®šä¹‰æ¨¡å¼ï¼šä½¿ç”¨ Agent é…ç½®çš„å·¥å…·
        base_tools = config["tools"]
    else:
        # é¢„è®¾æ¨¡å¼ï¼šä½¿ç”¨é¢„è®¾çš„å·¥å…·é›†
        base_tools = tool_presets.get(tools_mode, tool_presets["default"])

    # åº”ç”¨ç™½åå•
    if allowed_tools is not None:
        base_tools = [t for t in base_tools if t in allowed_tools]

    # åº”ç”¨é»‘åå•
    if disallowed_tools is not None:
        base_tools = [t for t in base_tools if t not in disallowed_tools]

    # è½¬æ¢ä¸ºå·¥å…·å¯¹è±¡
    tools: list[BaseTool] = [tool_map[t] for t in base_tools if t in tool_map]

    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
    context_retriever: ContextRetriever | None = None
    if enable_context_retrieval and project_root:
        try:
            context_retriever = ContextRetriever(project_root=project_root)
        except Exception as e:
            from .logging_config import get_logger

            logger = get_logger(__name__)
            logger.warning(f"ä¸Šä¸‹æ–‡æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    # é…ç½®system message
    bound_model = model.bind(system=config["system_prompt"])

    # åˆ›å»ºReAct Agent
    agent = create_react_agent(
        model=bound_model,
        tools=tools,
        checkpointer=checkpointer,
    )

    original_invoke = agent.invoke

    def invoke_with_context_and_confidence(
        input_data: dict[str, Any], *args: Any, **kwargs: Any
    ) -> Any:
        """åŒ…è£… invokeï¼šè‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡ + ç½®ä¿¡åº¦è¯„ä¼°"""

        # 1. è‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡
        if context_retriever and "messages" in input_data:
            messages = input_data["messages"]
            if messages:
                # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                last_message = messages[-1]
                query = (
                    last_message.content if hasattr(last_message, "content") else str(last_message)
                )

                # æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
                try:
                    context_docs = context_retriever.retrieve_context(
                        query=query, max_tokens=8000, max_docs=3
                    )

                    if context_docs:
                        # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
                        context_text = context_retriever.format_context(context_docs)

                        # å°†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼ˆsystem messageï¼‰
                        # æˆ–è€…ä½œä¸ºæ–°çš„ system message
                        from langchain_core.messages import SystemMessage

                        context_msg = SystemMessage(content=context_text)

                        # åœ¨ç”¨æˆ·æ¶ˆæ¯å‰æ’å…¥ä¸Šä¸‹æ–‡
                        input_data["messages"] = [context_msg] + messages

                        from .logging_config import get_logger

                        logger = get_logger(__name__)
                        logger.info(f"âœ“ è‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡: {len(context_docs)} ä¸ªæ–‡æ¡£")

                except Exception as e:
                    from .logging_config import get_logger

                    logger = get_logger(__name__)
                    logger.warning(f"ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥: {e}")

        # 2. è°ƒç”¨åŸå§‹ invoke
        result = original_invoke(input_data, *args, **kwargs)

        # 3. æ·»åŠ ç½®ä¿¡åº¦
        messages = result.get("messages") if isinstance(result, dict) else None
        confidence = _estimate_confidence(messages)
        if isinstance(result, dict):
            result["confidence"] = confidence

        return result

    agent.invoke = invoke_with_context_and_confidence  # type: ignore[assignment]
    return agent


def create_novel_agent(
    model: BaseChatModel | None = None,
    api_key: str | None = None,
    checkpointer: BaseCheckpointSaver[Any] | None = None,
    allowed_tools: list[str] | None = None,
    disallowed_tools: list[str] | None = None,
    tools_mode: str = "default",
) -> Any:
    """åˆ›å»ºå°è¯´å†™ä½œAgentï¼ˆå‘åå…¼å®¹ï¼‰

    Args:
        model: LLMæ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨Gemini 2.0 Flashï¼‰
        api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        checkpointer: ä¼šè¯æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
        allowed_tools: å…è®¸ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆç™½åå•ï¼‰
        disallowed_tools: ç¦æ­¢ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆé»‘åå•ï¼‰
        tools_mode: å·¥å…·æ¨¡å¼ï¼ˆdefault/minimal/customï¼‰

    Returns:
        ReAct Agentå®ä¾‹
    """
    return create_specialized_agent(
        "default",
        model,
        api_key,
        checkpointer,
        allowed_tools=allowed_tools,
        disallowed_tools=disallowed_tools,
        tools_mode=tools_mode,
    )


# ========== Tool Wrappers ==========


@tool
def read_file_tool(path: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹

    Args:
        path: æ–‡ä»¶è·¯å¾„

    Returns:
        æ–‡ä»¶å†…å®¹
    """
    return read_file(path)


@tool
def write_chapter_tool(number: int, content: str) -> str:
    """åˆ›å»ºæ–°ç« èŠ‚

    Args:
        number: ç« èŠ‚ç¼–å·ï¼ˆ1-999ï¼‰
        content: ç« èŠ‚å†…å®¹

    Returns:
        åˆ›å»ºçš„æ–‡ä»¶è·¯å¾„
    """
    return write_chapter(number, content)


@tool
def search_content_tool(keyword: str) -> str:
    """æœç´¢å…³é”®è¯

    Args:
        keyword: æœç´¢å…³é”®è¯

    Returns:
        åŒ¹é…ç»“æœï¼ˆæ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼‰
    """
    results = search_content(keyword)
    if not results:
        return f"æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„å†…å®¹"

    # æ ¼å¼åŒ–è¾“å‡º
    output = [f"æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…ç»“æœï¼š\n"]
    for i, r in enumerate(results[:10], 1):  # æœ€å¤šæ˜¾ç¤º 10 ä¸ªç»“æœ
        output.append(f"{i}. {r['file']}:{r['line']} - {r['content']}")

    if len(results) > 10:
        output.append(f"\n... è¿˜æœ‰ {len(results) - 10} ä¸ªç»“æœ")

    return "\n".join(output)


@tool
def verify_timeline_tool() -> str:
    """æ—¶é—´çº¿ç²¾ç¡®éªŒè¯ï¼ˆå¢å¼ºç‰ˆï¼šè¾“å‡ºè¡Œå·å’Œä¿®å¤å»ºè®®ï¼‰

    Returns:
        éªŒè¯ç»“æœï¼ˆæ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«æ–‡ä»¶åã€è¡Œå·ã€é”™è¯¯ç±»å‹ã€ä¿®å¤å»ºè®®ï¼‰
    """
    result = verify_strict_timeline()

    summary = result.get("summary", {})
    if summary.get("total_errors", 0) == 0 and summary.get("total_warnings", 0) == 0:
        return "âœ… æ—¶é—´çº¿æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°é—®é¢˜"

    output = []

    # è¾“å‡ºæ‘˜è¦
    output.append("ğŸ“Š æ—¶é—´çº¿éªŒè¯æ‘˜è¦ï¼š")
    output.append(f"  - é”™è¯¯: {summary.get('total_errors', 0)}")
    output.append(f"  - è­¦å‘Š: {summary.get('total_warnings', 0)}")
    output.append(f"  - å¯è‡ªåŠ¨ä¿®å¤: {'æ˜¯' if summary.get('auto_fixable') else 'å¦'}")
    output.append("")

    # è¾“å‡ºè¯¦ç»†é”™è¯¯
    if result["errors"]:
        output.append("âŒ å‘ç°æ—¶é—´çº¿é”™è¯¯ï¼š")
        for err in result["errors"]:
            file = err.get("file", "æœªçŸ¥")
            line = err.get("line", 0)
            msg = err.get("message", "")
            suggestion = err.get("suggestion", "")

            output.append(f"\n  ğŸ“„ {file}:{line}")
            output.append(f"     é—®é¢˜: {msg}")
            output.append(f"     å»ºè®®: {suggestion}")

    # è¾“å‡ºè­¦å‘Š
    if result["warnings"]:
        output.append("\nâš ï¸  æ—¶é—´çº¿è­¦å‘Šï¼š")
        for warn in result["warnings"]:
            file = warn.get("file", "æœªçŸ¥")
            line = warn.get("line", 0)
            msg = warn.get("message", "")
            suggestion = warn.get("suggestion", "")

            output.append(f"\n  ğŸ“„ {file}:{line}")
            output.append(f"     é—®é¢˜: {msg}")
            output.append(f"     å»ºè®®: {suggestion}")

    return "\n".join(output)


@tool
def verify_references_tool() -> str:
    """å¼•ç”¨å®Œæ•´æ€§éªŒè¯ï¼ˆå¢å¼ºç‰ˆï¼šè¾“å‡ºè¡Œå·å’Œä¿®å¤å»ºè®®ï¼‰

    Returns:
        éªŒè¯ç»“æœï¼ˆæ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«æ–‡ä»¶åã€è¡Œå·ã€é”™è¯¯ç±»å‹ã€ä¿®å¤å»ºè®®ï¼‰
    """
    result = verify_strict_references()

    summary = result.get("summary", {})
    if summary.get("total_errors", 0) == 0 and summary.get("total_warnings", 0) == 0:
        return "âœ… å¼•ç”¨æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°é—®é¢˜"

    output = []

    # è¾“å‡ºæ‘˜è¦
    output.append("ğŸ“Š å¼•ç”¨éªŒè¯æ‘˜è¦ï¼š")
    output.append(f"  - é”™è¯¯: {summary.get('total_errors', 0)}")
    output.append(f"  - è­¦å‘Š: {summary.get('total_warnings', 0)}")
    output.append(f"  - å¯è‡ªåŠ¨ä¿®å¤: {'æ˜¯' if summary.get('auto_fixable') else 'å¦'}")
    output.append("")

    # è¾“å‡ºè¯¦ç»†é”™è¯¯
    if result["errors"]:
        output.append("âŒ å‘ç°å¼•ç”¨é”™è¯¯ï¼š")
        for err in result["errors"]:
            file = err.get("file", "æœªçŸ¥")
            line = err.get("line", 0)
            msg = err.get("message", "")
            suggestion = err.get("suggestion", "")

            output.append(f"\n  ğŸ“„ {file}:{line}")
            output.append(f"     é—®é¢˜: {msg}")
            output.append(f"     å»ºè®®: {suggestion}")

    # è¾“å‡ºè­¦å‘Š
    if result["warnings"]:
        output.append("\nâš ï¸  å¼•ç”¨è­¦å‘Šï¼š")
        for warn in result["warnings"]:
            file = warn.get("file", "æœªçŸ¥")
            line = warn.get("line", 0)
            msg = warn.get("message", "")
            suggestion = warn.get("suggestion", "")

            output.append(f"\n  ğŸ“„ {file}:{line}")
            output.append(f"     é—®é¢˜: {msg}")
            output.append(f"     å»ºè®®: {suggestion}")

    return "\n".join(output)


@tool
def edit_chapter_lines_tool(
    chapter_number: int, start_line: int, end_line: int, new_content: str
) -> str:
    """ç²¾å‡†ä¿®æ”¹ç« èŠ‚çš„æŒ‡å®šè¡Œ

    ç”¨äºä¿®æ”¹ç« èŠ‚çš„ç‰¹å®šè¡Œï¼Œè€Œä¸æ˜¯é‡å†™æ•´ä¸ªç« èŠ‚ã€‚
    é€‚ç”¨åœºæ™¯ï¼šä¿®æ”¹å¯¹è¯ã€è°ƒæ•´æå†™ã€æ›´æ­£é”™è¯¯ç­‰ã€‚

    Args:
        chapter_number: ç« èŠ‚ç¼–å·ï¼ˆ1-999ï¼‰
        start_line: èµ·å§‹è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰
        end_line: ç»“æŸè¡Œå·ï¼ˆåŒ…å«ï¼Œä»1å¼€å§‹ï¼‰
        new_content: æ–°å†…å®¹ï¼ˆå°†æ›¿æ¢æŒ‡å®šè¡Œï¼‰

    Returns:
        æ“ä½œç»“æœæè¿°

    Example:
        # ä¿®æ”¹ç¬¬1ç« çš„ç¬¬10-12è¡Œ
        edit_chapter_lines_tool(1, 10, 12, "æ–°çš„æ®µè½å†…å®¹\\nå¯ä»¥æ˜¯å¤šè¡Œ")
    """
    return edit_chapter_lines(chapter_number, start_line, end_line, new_content)


@tool
def replace_in_file_tool(
    file_path: str, search_text: str, replacement: str, occurrence: int | None = None
) -> str:
    """åœ¨æ–‡ä»¶ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢æ–‡æœ¬

    ç”¨äºæ‰¹é‡æ›¿æ¢æ–‡ä»¶ä¸­çš„æ–‡æœ¬ï¼Œæ”¯æŒå…¨éƒ¨æ›¿æ¢æˆ–æŒ‡å®šç¬¬Næ¬¡å‡ºç°ã€‚
    é€‚ç”¨åœºæ™¯ï¼šè§’è‰²æ”¹åã€åœ°åä¿®æ”¹ã€æœ¯è¯­ç»Ÿä¸€ç­‰ã€‚

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "chapters/ch001.md"ï¼‰
        search_text: è¦æŸ¥æ‰¾çš„æ–‡æœ¬
        replacement: æ›¿æ¢æ–‡æœ¬
        occurrence: æ›¿æ¢ç¬¬å‡ æ¬¡å‡ºç°ï¼ˆNone=å…¨éƒ¨æ›¿æ¢ï¼Œ1=ç¬¬ä¸€æ¬¡ï¼Œ2=ç¬¬äºŒæ¬¡...ï¼‰

    Returns:
        æ“ä½œç»“æœæè¿°

    Example:
        # å°†æ‰€æœ‰"å¼ ä¸‰"æ›¿æ¢ä¸º"æå››"
        replace_in_file_tool("chapters/ch001.md", "å¼ ä¸‰", "æå››")

        # åªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°çš„"å¼ ä¸‰"
        replace_in_file_tool("chapters/ch001.md", "å¼ ä¸‰", "æå››", 1)
    """
    return replace_in_file(file_path, search_text, replacement, occurrence)


@tool
def multi_edit_tool(operations: str) -> str:
    """æ‰¹é‡ç¼–è¾‘å¤šä¸ªæ–‡ä»¶

    ç”¨äºä¸€æ¬¡æ€§ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼Œæ”¯æŒåŸå­æ€§æ“ä½œï¼ˆå…¨éƒ¨æˆåŠŸæˆ–å…¨éƒ¨å›æ»šï¼‰ã€‚
    é€‚ç”¨åœºæ™¯ï¼šæ‰¹é‡è§’è‰²æ”¹åã€ç»Ÿä¸€æœ¯è¯­ã€å¤šç« èŠ‚åŒæ­¥ä¿®æ”¹ç­‰ã€‚

    Args:
        operations: JSONæ ¼å¼çš„æ“ä½œåˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š
            ```json
            [
                {
                    "type": "replace",
                    "file": "chapters/ch001.md",
                    "search": "å¼ ä¸‰",
                    "replace": "æå››"
                },
                {
                    "type": "replace",
                    "file": "chapters/ch002.md",
                    "search": "å¼ ä¸‰",
                    "replace": "æå››"
                }
            ]
            ```

    Returns:
        æ“ä½œç»“æœæè¿°

    Note:
        å¦‚æœä»»ä½•ä¸€ä¸ªæ“ä½œå¤±è´¥ï¼Œæ‰€æœ‰ä¿®æ”¹ä¼šè‡ªåŠ¨å›æ»š
    """
    import json

    try:
        ops_list = json.loads(operations)
        return multi_edit(ops_list)
    except json.JSONDecodeError as e:
        return f"âŒ JSONæ ¼å¼é”™è¯¯: {e}"


@tool
def smart_context_search(
    query: str, search_type: str = "all", max_hops: int = 2, limit: int = 10
) -> str:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡æœç´¢ï¼ˆåŸºäºå›¾æ•°æ®åº“ï¼‰

    ä½¿ç”¨ NervusDB å›¾æ•°æ®åº“è¿›è¡Œæ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼Œæ¯”å‘é‡æ£€ç´¢æ›´ç²¾å‡†ã€æ›´å¯è§£é‡Šã€‚
    é€šè¿‡å›¾éå†æ‰¾å‡ºæ‰€æœ‰ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬ç›´æ¥åŒ¹é…å’Œå…³ç³»å…³è”ã€‚

    Args:
        query: æœç´¢æŸ¥è¯¢ï¼ˆå¦‚"å¼ ä¸‰å’Œæå››çš„å…³ç³»"ï¼‰
        search_type: æœç´¢ç±»å‹
            - 'character': åªæœç´¢è§’è‰²
            - 'location': åªæœç´¢åœ°ç‚¹
            - 'event': åªæœç´¢äº‹ä»¶
            - 'foreshadow': åªæœç´¢ä¼ç¬”
            - 'all': æ‰€æœ‰ç±»å‹ï¼ˆé»˜è®¤ï¼‰
        max_hops: æœ€å¤§å…³ç³»è·³æ•°ï¼ˆ1-3ï¼Œé»˜è®¤ 2ï¼‰
        limit: æœ€å¤šè¿”å›ç»“æœæ•°ï¼ˆé»˜è®¤ 10ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„æœç´¢ç»“æœï¼ŒåŒ…å«ï¼š
        - ç›´æ¥åŒ¹é…çš„å®ä½“
        - é€šè¿‡å…³ç³»å…³è”çš„å®ä½“
        - å›¾è·¯å¾„å’Œç½®ä¿¡åº¦
        - ç»Ÿè®¡ä¿¡æ¯

    Example:
        # æœç´¢è§’è‰²"å¼ ä¸‰"çš„æ‰€æœ‰ç›¸å…³å†…å®¹
        smart_context_search("å¼ ä¸‰", "character", max_hops=2)

        # æœç´¢æ‰€æœ‰åŒ…å«"åŒ—äº¬"çš„å†…å®¹
        smart_context_search("åŒ—äº¬", "all", max_hops=1)
    """
    return smart_context_search_tool(query, search_type, max_hops, limit)


@tool
def build_character_network(character_names: str | None = None) -> str:
    """æ„å»ºè§’è‰²å…³ç³»ç½‘ç»œå›¾

    åˆ†æè§’è‰²ä¹‹é—´çš„å…³ç³»ï¼Œæ„å»ºç¤¾äº¤ç½‘ç»œå›¾ï¼Œå¹¶è¿›è¡Œç¤¾åŒºæ£€æµ‹ã€‚

    Args:
        character_names: è§’è‰²ååˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚"å¼ ä¸‰,æå››,ç‹äº”"ï¼‰
                        ç•™ç©ºåˆ™åˆ†ææ‰€æœ‰è§’è‰²

    Returns:
        æ ¼å¼åŒ–çš„ç½‘ç»œä¿¡æ¯ï¼š
        - èŠ‚ç‚¹ï¼ˆè§’è‰²ï¼‰åˆ—è¡¨
        - è¾¹ï¼ˆå…³ç³»ï¼‰åˆ—è¡¨
        - ç¤¾åŒºï¼ˆç¾¤ç»„ï¼‰æ£€æµ‹ç»“æœ

    Example:
        # åˆ†ææ‰€æœ‰è§’è‰²çš„å…³ç³»
        build_character_network()

        # åªåˆ†ææŒ‡å®šè§’è‰²çš„å…³ç³»
        build_character_network("å¼ ä¸‰,æå››,ç‹äº”")
    """
    return build_character_network_tool(character_names)


@tool
def trace_foreshadow(foreshadow_id: str) -> str:
    """è¿½æº¯ä¼ç¬”å®Œæ•´é“¾æ¡

    è¿½è¸ªä¼ç¬”ä»åŸ‹ä¸‹åˆ°æ­æ™“çš„å®Œæ•´è¿‡ç¨‹ï¼Œå¸®åŠ©æ£€æŸ¥ä¼ç¬”æ˜¯å¦è¢«æ­£ç¡®å¤„ç†ã€‚

    Args:
        foreshadow_id: ä¼ç¬” IDï¼ˆå¦‚ "foreshadow_001"ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„ä¼ç¬”è¿½æº¯ç»“æœï¼š
        - Setupï¼ˆåŸ‹ç¬”ï¼‰ç« èŠ‚
        - Hintsï¼ˆæš—ç¤ºï¼‰åˆ—è¡¨
        - Revealï¼ˆæ­æ™“ï¼‰ç« èŠ‚
        - çŠ¶æ€ï¼ˆå·²è§£å†³/æœªè§£å†³ï¼‰

    Example:
        # è¿½æº¯ä¼ç¬” "foreshadow_001"
        trace_foreshadow("foreshadow_001")
    """
    return trace_foreshadow_tool(foreshadow_id)


def _estimate_confidence(messages: Any) -> int:
    """è¯„ä¼° Agent è¾“å‡ºçš„ç½®ä¿¡åº¦ï¼ˆ0-100ï¼‰

    è¯„åˆ†æ ‡å‡†ï¼š
    1. åŸºç¡€åˆ†ï¼ˆ50åˆ†ï¼‰ï¼šè¾“å‡ºé•¿åº¦é€‚ä¸­ï¼ˆ50-300å­—ï¼‰
    2. ç»“æ„åŒ–åŠ åˆ†ï¼ˆ30åˆ†ï¼‰ï¼š
       - æœ‰å®Œæ•´å¥å­ç»“æ„ï¼ˆ10åˆ†ï¼‰
       - æœ‰æ¡ç†ï¼ˆåˆ—è¡¨/æ ‡é¢˜ï¼‰ï¼ˆ10åˆ†ï¼‰
       - æœ‰å…·ä½“å»ºè®®/å¼•ç”¨ï¼ˆ10åˆ†ï¼‰
    3. è´¨é‡åŠ åˆ†ï¼ˆ20åˆ†ï¼‰ï¼š
       - åŒ…å«æ–‡ä»¶è·¯å¾„/è¡Œå·ï¼ˆ10åˆ†ï¼‰
       - åŒ…å«å…·ä½“ç¤ºä¾‹ï¼ˆ10åˆ†ï¼‰
    4. æ‰£åˆ†é¡¹ï¼š
       - é”™è¯¯æ ‡è®°ï¼ˆâŒï¼‰ï¼šæ¯ä¸ªæ‰£5åˆ†
       - ç©ºæ´å›ç­”ï¼ˆ"ä¸æ¸…æ¥š"/"ä¸ç¡®å®š"ç­‰ï¼‰ï¼šæ‰£20åˆ†
    """
    if not isinstance(messages, list) or not messages:
        return 0

    last = messages[-1]
    content = getattr(last, "content", None) or str(last)

    # åŸºç¡€åˆ†ï¼šæ ¹æ®è¾“å‡ºé•¿åº¦
    words = len(content.split())
    if words < 20:
        base_score = 20  # å¤ªçŸ­
    elif 20 <= words <= 300:
        base_score = 50  # é€‚ä¸­
    else:
        base_score = 40  # å¤ªé•¿å¯èƒ½å†—ä½™

    # ç»“æ„åŒ–åŠ åˆ†
    structure_score = 0
    sentences = content.count("ã€‚") + content.count("ï¼") + content.count("ï¼Ÿ") + content.count(".")
    if sentences >= 3:
        structure_score += 10  # æœ‰å®Œæ•´å¥å­

    # æœ‰åˆ—è¡¨æˆ–æ ‡é¢˜
    if any(marker in content for marker in ["- ", "* ", "1.", "2.", "##", "###"]):
        structure_score += 10

    # æœ‰å…·ä½“å»ºè®®æˆ–å¼•ç”¨
    if any(
        keyword in content
        for keyword in ["å»ºè®®", "æ¨è", "å¯ä»¥", "[REF:", "[TIME:", "spec/", "chapters/"]
    ):
        structure_score += 10

    # è´¨é‡åŠ åˆ†
    quality_score = 0
    # åŒ…å«æ–‡ä»¶è·¯å¾„/è¡Œå·
    if any(pattern in content for pattern in [".md", "Line ", "ç¬¬", "è¡Œ"]):
        quality_score += 10

    # åŒ…å«å…·ä½“ç¤ºä¾‹
    if "```" in content or "ä¾‹å¦‚" in content or "æ¯”å¦‚" in content:
        quality_score += 10

    # æ‰£åˆ†é¡¹
    penalty = 0
    penalty += content.count("âŒ") * 5  # é”™è¯¯æ ‡è®°
    if any(
        phrase in content for phrase in ["ä¸æ¸…æ¥š", "ä¸ç¡®å®š", "æ— æ³•åˆ¤æ–­", "éœ€è¦æ›´å¤šä¿¡æ¯", "ä¸çŸ¥é“"]
    ):
        penalty += 20  # ç©ºæ´å›ç­”

    # è®¡ç®—æ€»åˆ†
    total = base_score + structure_score + quality_score - penalty
    return max(0, min(100, total))
